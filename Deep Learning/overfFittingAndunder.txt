# # Underfitting and Overfitting in Deep Learning

# ## Underfitting

# Underfitting occurs when a model is too simple to capture the underlying patterns in the training data, resulting in poor performance on both the training and test sets. This can be due to:

# * Insufficient model capacity (e.g., too few layers or neurons)
# * Inadequate training data
# * Poor model architecture

# ## Overfitting

# Overfitting occurs when a model is too complex and learns the noise in the training data, resulting in excellent performance on the training set but poor performance on the test set. This can be due to:

# * Excessive model capacity (e.g., too many layers or neurons)
# * Overtraining (e.g., training for too many epochs)
# * Insufficient regularization

# ## Example Code

# ```python
# import numpy as np
# import matplotlib.pyplot as plt
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LinearRegression
# from sklearn.preprocessing import PolynomialFeatures
# from sklearn.pipeline import make_pipeline

# # Generate sample data
# np.random.seed(0)
# X = np.random.rand(100, 1)
# y = 3 * X + 2 + np.random.randn(100, 1)

# # Split data into training and test sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Underfitting example: simple linear regression
# model_underfit = LinearRegression()
# model_underfit.fit(X_train, y_train)
# y_pred_underfit = model_underfit.predict(X_test)

# # Overfitting example: high-degree polynomial regression
# model_overfit = make_pipeline(PolynomialFeatures(degree=10), LinearRegression())
# model_overfit.fit(X_train, y_train)
# y_pred_overfit = model_overfit.predict(X_test)

# # Plot results
# plt.scatter(X_test, y_test, label='Test data')
# plt.plot(X_test, y_pred_underfit, label='Underfitting model')
# plt.plot(X_test, y_pred_overfit, label='Overfitting model')
# plt.legend()
# plt.show()
# ```